{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jigeesha.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPrsSqDC0g+9ckym5IsS5zX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AKHIL-882/Sentimental-Analysis-on-User-Emotions/blob/main/Sentimental%20Analysis%20on%20User%20Emotions%201.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8l-9viKYXSd"
      },
      "source": [
        "### **1.1 Installing the required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp36yvTewTuH",
        "outputId": "e475a6d5-d2e6-44c2-90df-07cabf736029"
      },
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install gtts"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 1s (5,475 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 160706 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/e6/a4e9fc8a93c1318540e8de6d8d4beb5749b7960388a7c7f27799fc2dd016/pytesseract-0.3.7.tar.gz\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.7-py2.py3-none-any.whl size=13945 sha256=f188808b8049441c74ab8a744d735b6553f37fbd45923ded71a4a75b59d611d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/20/7e/1dd0daad1575d5260916bb1e9781246430647adaef4b3ca3b3\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.7\n",
            "Collecting gtts\n",
            "  Downloading https://files.pythonhosted.org/packages/5f/b9/94e59337107be134b21ce395a29fc0715b707b560108d6797de2d93e1178/gTTS-2.2.2-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gtts) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from gtts) (8.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gtts) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gtts) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gtts) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gtts) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gtts) (2.10)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX9MxwwaYjtJ"
      },
      "source": [
        "### **1.2 Importing the required modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm9mor4mwRoM"
      },
      "source": [
        "import pytesseract\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "try:\n",
        " from PIL import Image\n",
        "except ImportError:\n",
        " import Image"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXShc4f5YoNV"
      },
      "source": [
        "### **1.3 Text Detection from Image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pDH9osevqlJ",
        "outputId": "a716a771-11c9-48cd-c02b-ed63603589fb"
      },
      "source": [
        "\n",
        "# Enter the path of the image\n",
        "path='jigee.jpg'\n",
        "info_text = pytesseract.image_to_string(Image.open(path))\n",
        "print(info_text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "€ NSEC\n",
            "\n",
            "12 minutes ago\n",
            "\n",
            "   \n",
            "\n",
            "The Matrix Reloaded\n",
            "ya\n",
            "Included with Prime\n",
            "\n",
            " \n",
            "\n",
            "S RZ a ee\n",
            "\n",
            "Sela aeg b@elp ate) Cie Watchlist rc\n",
            "\n",
            "Neo, Trinity & Morpheus lead revolt against Machine Army\n",
            "unteashing their arsenal of extraordinary skills & weaponry against\n",
            "\n",
            "Réleased in 2003 'With those high standard\n",
            "visuals:.... @ @ this movie got better CGI than\n",
            "most of our present films  #ante mundhu parts\n",
            "chudaledhu kabatti ...movie em ardam kaledhu...\n",
            "adhi vere vishyam @®\n",
            "\n",
            "Riad\n",
            "\f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXuYDdn9t2Lt"
      },
      "source": [
        "### **1.4 Copyting the data into file**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRVGZqSytm1p"
      },
      "source": [
        "f = open(\"status_text.txt\", \"w\")\n",
        "f.write(info_text)\n",
        "f.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv-MUcoSvioe"
      },
      "source": [
        "### **1.5 Converting the text into array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAOkKZmGtmyb",
        "outputId": "cffab65d-7e0f-443c-c81f-78c2d1bd2ba8"
      },
      "source": [
        "status_text = info_text.split()\n",
        "status_text"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['€',\n",
              " 'NSEC',\n",
              " '12',\n",
              " 'minutes',\n",
              " 'ago',\n",
              " 'The',\n",
              " 'Matrix',\n",
              " 'Reloaded',\n",
              " 'ya',\n",
              " 'Included',\n",
              " 'with',\n",
              " 'Prime',\n",
              " 'S',\n",
              " 'RZ',\n",
              " 'a',\n",
              " 'ee',\n",
              " 'Sela',\n",
              " 'aeg',\n",
              " 'b@elp',\n",
              " 'ate)',\n",
              " 'Cie',\n",
              " 'Watchlist',\n",
              " 'rc',\n",
              " 'Neo,',\n",
              " 'Trinity',\n",
              " '&',\n",
              " 'Morpheus',\n",
              " 'lead',\n",
              " 'revolt',\n",
              " 'against',\n",
              " 'Machine',\n",
              " 'Army',\n",
              " 'unteashing',\n",
              " 'their',\n",
              " 'arsenal',\n",
              " 'of',\n",
              " 'extraordinary',\n",
              " 'skills',\n",
              " '&',\n",
              " 'weaponry',\n",
              " 'against',\n",
              " 'Réleased',\n",
              " 'in',\n",
              " '2003',\n",
              " \"'With\",\n",
              " 'those',\n",
              " 'high',\n",
              " 'standard',\n",
              " 'visuals:....',\n",
              " '@',\n",
              " '@',\n",
              " 'this',\n",
              " 'movie',\n",
              " 'got',\n",
              " 'better',\n",
              " 'CGI',\n",
              " 'than',\n",
              " 'most',\n",
              " 'of',\n",
              " 'our',\n",
              " 'present',\n",
              " 'films',\n",
              " '#ante',\n",
              " 'mundhu',\n",
              " 'parts',\n",
              " 'chudaledhu',\n",
              " 'kabatti',\n",
              " '...movie',\n",
              " 'em',\n",
              " 'ardam',\n",
              " 'kaledhu...',\n",
              " 'adhi',\n",
              " 'vere',\n",
              " 'vishyam',\n",
              " '@®',\n",
              " 'Riad']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW4EkNxmv4WA"
      },
      "source": [
        "### **1.6 Converting the text into lowercases**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h8e-CnttmwI",
        "outputId": "6055ec4d-12ac-49d9-d305-3cc3646c2e08"
      },
      "source": [
        "for i in range(len(status_text)):\n",
        "   status_text[i] = status_text[i].lower()\n",
        "print(status_text)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['€', 'nsec', '12', 'minutes', 'ago', 'the', 'matrix', 'reloaded', 'ya', 'included', 'with', 'prime', 's', 'rz', 'a', 'ee', 'sela', 'aeg', 'b@elp', 'ate)', 'cie', 'watchlist', 'rc', 'neo,', 'trinity', '&', 'morpheus', 'lead', 'revolt', 'against', 'machine', 'army', 'unteashing', 'their', 'arsenal', 'of', 'extraordinary', 'skills', '&', 'weaponry', 'against', 'réleased', 'in', '2003', \"'with\", 'those', 'high', 'standard', 'visuals:....', '@', '@', 'this', 'movie', 'got', 'better', 'cgi', 'than', 'most', 'of', 'our', 'present', 'films', '#ante', 'mundhu', 'parts', 'chudaledhu', 'kabatti', '...movie', 'em', 'ardam', 'kaledhu...', 'adhi', 'vere', 'vishyam', '@®', 'riad']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6pVURvvwH7L"
      },
      "source": [
        "### **1.7 Removing the articles and conjunction** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjdMI9V2tmtS",
        "outputId": "44001322-a36e-4c6b-d17f-4298ded829eb"
      },
      "source": [
        "remove_elements = {'a','of','only','for','an','they','to','let','me', 'aboard',\n",
        "'about',\n",
        "'above',\n",
        "'across',\n",
        "'after',\n",
        "'against',\n",
        "'along',\n",
        "'amid',\n",
        "'among',\n",
        "'anti',\n",
        "'around',\n",
        "'as',\n",
        "'at',\n",
        "'before',\n",
        "'behind',\n",
        "'below',\n",
        "'beneath',\n",
        "'beside',\n",
        "'besides',\n",
        "'between',\n",
        "'beyond',\n",
        "'but',\n",
        "'by',\n",
        "'concerning',\n",
        "'considering',\n",
        "'despite',\n",
        "'down',\n",
        "'during',\n",
        "'except',\n",
        "'excepting',\n",
        "'excluding',\n",
        "'following',\n",
        "'for',\n",
        "'from',\n",
        "'in',\n",
        "'inside',\n",
        "'into',\n",
        "'like',\n",
        "'minus',\n",
        "'near',\n",
        "'of',\n",
        "'off',\n",
        "'on',\n",
        "'onto',\n",
        "'opposite',\n",
        "'outside',\n",
        "'over',\n",
        "'past',\n",
        "'per',\n",
        "'plus',\n",
        "'regarding',\n",
        "'round',\n",
        "'save',\n",
        "'since',\n",
        "'than',\n",
        "'through',\n",
        "'to',\n",
        "'toward',\n",
        "'towards',\n",
        "'under',\n",
        "'underneath',\n",
        "'unlike',\n",
        "'until',\n",
        "'up',\n",
        "'upon',\n",
        "'versus',\n",
        "'via',\n",
        "'with',\n",
        "'within',\n",
        "'without',\n",
        "'the'}\n",
        "\n",
        "status_text = [ele for ele in status_text if ele not in remove_elements]\n",
        "print(status_text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['€', 'nsec', '12', 'minutes', 'ago', 'matrix', 'reloaded', 'ya', 'included', 'prime', 's', 'rz', 'ee', 'sela', 'aeg', 'b@elp', 'ate)', 'cie', 'watchlist', 'rc', 'neo,', 'trinity', '&', 'morpheus', 'lead', 'revolt', 'machine', 'army', 'unteashing', 'their', 'arsenal', 'extraordinary', 'skills', '&', 'weaponry', 'réleased', '2003', \"'with\", 'those', 'high', 'standard', 'visuals:....', '@', '@', 'this', 'movie', 'got', 'better', 'cgi', 'most', 'our', 'present', 'films', '#ante', 'mundhu', 'parts', 'chudaledhu', 'kabatti', '...movie', 'em', 'ardam', 'kaledhu...', 'adhi', 'vere', 'vishyam', '@®', 'riad']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNXC7OOoymXQ"
      },
      "source": [
        "### **1.8 Gathering Happy related text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqpzV8hLtmqx",
        "outputId": "4dcc49df-5ca5-4390-d4b5-ada080db2902"
      },
      "source": [
        "happy_text = ['cheerful',\n",
        "'contented',\n",
        "'delighted',\n",
        "'ecstatic',\n",
        "'elated',\n",
        "'glad',\n",
        "'joyful',\n",
        "'joyous',\n",
        "'jubilant',\n",
        "'extraordinary',\n",
        "'lively',\n",
        "'merry',\n",
        "'overjoyed',\n",
        "'peaceful',\n",
        "'pleasant',\n",
        "'pleased',\n",
        "'thrilled',\n",
        "'upbeat',\n",
        "'blessed',\n",
        "'blest',\n",
        "'blissful',\n",
        "'blithe',\n",
        "'captivated',\n",
        "'chipper',\n",
        "'chirpy',\n",
        "'content',\n",
        "'convivial',\n",
        "'exultant',\n",
        "'flying high',\n",
        "'gay',\n",
        "'gleeful',\n",
        "'gratified',\n",
        "'intoxicated',\n",
        "'jolly',\n",
        "'laughing',\n",
        "'light',\n",
        "'looking good',\n",
        "'mirthful',\n",
        "'on cloud nine',\n",
        "'peppy',\n",
        "'perky,'\n",
        "'playful',\n",
        "'sparkling',\n",
        "'sunny',\n",
        "'tickled',\n",
        "'tickled pink',\n",
        "'up',\n",
        "'walking on air',]\n",
        "\n",
        "\n",
        "print(type(happy_text))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYXdDIaP0ioV"
      },
      "source": [
        "### **1.9 Converting the Happy Text into token of values**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAuOumG9tmJv",
        "outputId": "1f480222-984f-469a-90e2-3519edba0581"
      },
      "source": [
        "import numpy as np\n",
        "happy_text = np.asarray(happy_text)\n",
        "\n",
        "for i in range(len(happy_text)):\n",
        "   happy_text[i] = happy_text[i].lower()\n",
        "\n",
        "\n",
        "print(happy_text)\n",
        "print(type(happy_text))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cheerful' 'contented' 'delighted' 'ecstatic' 'elated' 'glad' 'joyful'\n",
            " 'joyous' 'jubilant' 'extraordinary' 'lively' 'merry' 'overjoyed'\n",
            " 'peaceful' 'pleasant' 'pleased' 'thrilled' 'upbeat' 'blessed' 'blest'\n",
            " 'blissful' 'blithe' 'captivated' 'chipper' 'chirpy' 'content' 'convivial'\n",
            " 'exultant' 'flying high' 'gay' 'gleeful' 'gratified' 'intoxicated'\n",
            " 'jolly' 'laughing' 'light' 'looking good' 'mirthful' 'on cloud nine'\n",
            " 'peppy' 'perky,playful' 'sparkling' 'sunny' 'tickled' 'tickled pink' 'up'\n",
            " 'walking on air']\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWFLrZO41UHI"
      },
      "source": [
        "### **2.0 Gathering Sad realated text**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysESsP5n01Zo"
      },
      "source": [
        "sad_text = [\n",
        "'bitter',\n",
        "'dismal',\n",
        "'heartbroken',\n",
        "'melancholy',\n",
        "'mournful',\n",
        "'pessimistic',\n",
        "'somber',\n",
        "'sorrowful',\n",
        "'sorry',\n",
        "'wistful',\n",
        "'bereaved',\n",
        "'blue',\n",
        "'cheerless',\n",
        "'dejected',\n",
        "'despairing',\n",
        "'despondent',\n",
        "'disconsolate',\n",
        "'distressed',\n",
        "'doleful',\n",
        "'down',\n",
        "'down in dumps',\n",
        "'down in mouth',\n",
        "'downcast',\n",
        "'forlorn',\n",
        "'gloomy',\n",
        "'glum',\n",
        "'grief-stricken',\n",
        "'grieved',\n",
        "'heartsick',\n",
        "'heavyhearted',\n",
        "'hurting',\n",
        "'in doldrums',\n",
        "'in grief',\n",
        "'in the dumps',\n",
        "'languishing',\n",
        "'low',\n",
        "'low-spirited',\n",
        "'lugubrious',\n",
        "'morbid',\n",
        "'morose',\n",
        "'out of sorts',\n",
        "'pensive',\n",
        "'sick at heart',\n",
        "'troubled',\n",
        "'weeping',\n",
        "'woebegone']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su_X-CSy1-Z3"
      },
      "source": [
        "### **2.1 Convering Sad Text into token of Array values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owDfoHmP1-EH",
        "outputId": "7e7c7515-4fd5-45e6-bd22-64f2e669742b"
      },
      "source": [
        "import numpy as np\n",
        "sad_text = np.asarray(sad_text)\n",
        "\n",
        "for i in range(len(sad_text)):\n",
        "   sad_text[i] = sad_text[i].lower()\n",
        "\n",
        "\n",
        "print(sad_text)\n",
        "print(type(sad_text))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bitter' 'dismal' 'heartbroken' 'melancholy' 'mournful' 'pessimistic'\n",
            " 'somber' 'sorrowful' 'sorry' 'wistful' 'bereaved' 'blue' 'cheerless'\n",
            " 'dejected' 'despairing' 'despondent' 'disconsolate' 'distressed'\n",
            " 'doleful' 'down' 'down in dumps' 'down in mouth' 'downcast' 'forlorn'\n",
            " 'gloomy' 'glum' 'grief-stricken' 'grieved' 'heartsick' 'heavyhearted'\n",
            " 'hurting' 'in doldrums' 'in grief' 'in the dumps' 'languishing' 'low'\n",
            " 'low-spirited' 'lugubrious' 'morbid' 'morose' 'out of sorts' 'pensive'\n",
            " 'sick at heart' 'troubled' 'weeping' 'woebegone']\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP02gGnE1-Cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aefa9b11-de37-450f-b2a4-c37625859c71"
      },
      "source": [
        "happy_count = 0\n",
        "sad_count = 0\n",
        "for i in range(0,len(status_text)):\n",
        "  for j in range(0,len(happy_text)):\n",
        "    if(happy_text[j] == status_text[i]):\n",
        "      print(\"match\", status_text[i])\n",
        "      happy_count+=1\n",
        "  for j in range(0,len(sad_text)):\n",
        "    if(sad_text[j] == status_text[i]):\n",
        "      print(\"match\", status[i])\n",
        "      sad_count+=1\n",
        "\n",
        "if((happy_count == 0) and (sad_count ==0)):\n",
        "  print(\"The user emotions are neutral\")\n",
        "elif(happy_count>sad_count):\n",
        "  print(\"The user is happy in state\")\n",
        "else:\n",
        "  print(\"The user is emotional. Need to take care\")\n",
        "print(\"Happy Index   |||   Sad Index\")\n",
        "print(happy_count,\"            |||    \", sad_count)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "match extraordinary\n",
            "The user is happy in state\n",
            "Happy Index   |||   Sad Index\n",
            "1             |||     0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diEWsdC-1-AB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEF_5ixS1983"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}